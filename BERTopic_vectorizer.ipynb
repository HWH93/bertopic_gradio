{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "import gensim.corpora as corpora\n",
    "from sentence_transformers import SentenceTransformer\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Load data\n",
    "lucy = pd.read_csv('/workspace/data/실시간검색어20230110.csv')\n",
    "lucy['내용'] = lucy['내용'].replace(np.nan, '')\n",
    "lucy['내용'] = lucy['내용'].replace(\"\\n\", '')\n",
    "# Filter\n",
    "\n",
    "lucy.내용 = lucy.apply(lambda row: \" \".join(re.sub(\"[-=+,#/\\?:^$.@*\\\"※~&%ㆍ!』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…《\\》]\", \" \", row.내용).split()), 1)\n",
    "lucy.내용 = lucy.apply(lambda row: \" \".join(re.sub(\"([ㄱ-ㅎㅏ-ㅣ]+)\", \" \", row.내용).split()), 1)\n",
    "lucy.내용 = lucy.apply(lambda row: \" \".join(re.sub(\"([♡❤✌❣♥ᆢ✊❤️✨⤵️☺️;”“]+)\", \" \", row.내용).split()), 1)\n",
    "lucy.내용 = lucy.apply(lambda row: \" \".join(re.sub(\"_x000D_\", \"\", row.내용).split()), 1)\n",
    "timestamps = lucy.수집일.to_list()\n",
    "contents_data = lucy.내용.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def _preprocess_text(self, documents: np.ndarray) -> List[str]:\n",
    "\n",
    "    cleaned_documents = [doc.replace(\"\\n\", \" \") for doc in documents]\n",
    "    cleaned_documents = [doc.replace(\"\\t\", \" \") for doc in cleaned_documents]\n",
    "    if self.language == \"english\":\n",
    "        cleaned_documents = [re.sub(r'[^A-Za-z0-9 ]+', '', doc) for doc in cleaned_documents]\n",
    "    cleaned_documents = [doc if doc != \"\" else \"emptydoc\" for doc in cleaned_documents]\n",
    "    return cleaned_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pd.DataFrame({\"Document\": contents_data,\n",
    "                          \"ID\": range(len(contents_data)),\n",
    "                          \"Topic\": topics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(min_df=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcorpus=vectorizer.transform(contents_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4097, 163185)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcorpus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sparse matrix length is ambiguous; use getnnz() or shape[0]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/workspace/BERTopic_vectorizer.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f706963227d/workspace/BERTopic_vectorizer.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m topic_model \u001b[39m=\u001b[39m SentenceTransformer(\u001b[39m'\u001b[39m\u001b[39mjhgan/ko-sbert-sts\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell://attached-container%2B7b22636f6e7461696e65724e616d65223a222f746f706963227d/workspace/BERTopic_vectorizer.ipynb#W1sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m corpus \u001b[39m=\u001b[39m topic_model\u001b[39m.\u001b[39;49mencode(vcorpus)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sentence_transformers/SentenceTransformer.py:156\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, batch_size, show_progress_bar, output_value, convert_to_numpy, convert_to_tensor, device, normalize_embeddings)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    155\u001b[0m all_embeddings \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 156\u001b[0m length_sorted_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort([\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_text_length(sen) \u001b[39mfor\u001b[39;00m sen \u001b[39min\u001b[39;00m sentences])\n\u001b[1;32m    157\u001b[0m sentences_sorted \u001b[39m=\u001b[39m [sentences[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m length_sorted_idx]\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m start_index \u001b[39min\u001b[39;00m trange(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(sentences), batch_size, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatches\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sentence_transformers/SentenceTransformer.py:156\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m    155\u001b[0m all_embeddings \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 156\u001b[0m length_sorted_idx \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39margsort([\u001b[39m-\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_text_length(sen) \u001b[39mfor\u001b[39;00m sen \u001b[39min\u001b[39;00m sentences])\n\u001b[1;32m    157\u001b[0m sentences_sorted \u001b[39m=\u001b[39m [sentences[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m length_sorted_idx]\n\u001b[1;32m    159\u001b[0m \u001b[39mfor\u001b[39;00m start_index \u001b[39min\u001b[39;00m trange(\u001b[39m0\u001b[39m, \u001b[39mlen\u001b[39m(sentences), batch_size, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatches\u001b[39m\u001b[39m\"\u001b[39m, disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m show_progress_bar):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/sentence_transformers/SentenceTransformer.py:568\u001b[0m, in \u001b[0;36mSentenceTransformer._text_length\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(text, \u001b[39m'\u001b[39m\u001b[39m__len__\u001b[39m\u001b[39m'\u001b[39m):      \u001b[39m#Object has no len() method\u001b[39;00m\n\u001b[1;32m    567\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 568\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mlen\u001b[39;49m(text) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(text[\u001b[39m0\u001b[39m], \u001b[39mint\u001b[39m):    \u001b[39m#Empty string or list of ints\u001b[39;00m\n\u001b[1;32m    569\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mlen\u001b[39m(text)\n\u001b[1;32m    570\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/scipy/sparse/_base.py:345\u001b[0m, in \u001b[0;36mspmatrix.__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__len__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 345\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msparse matrix length is ambiguous; use getnnz()\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    346\u001b[0m                     \u001b[39m\"\u001b[39m\u001b[39m or shape[0]\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: sparse matrix length is ambiguous; use getnnz() or shape[0]"
     ]
    }
   ],
   "source": [
    "topic_model = SentenceTransformer('jhgan/ko-sbert-sts')\n",
    "corpus = topic_model.encode(vcorpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vcorpus=vectorizer.fit(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_data\n",
    "\n",
    "topics=['인공위성', '지진', '미국증시', '더글로리', '송중기', '너클', '성남의혹']\n",
    "df['topics'] = [topics.index(line) for line in df['검색어']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import plotly.express as px\n",
    "import hdbscan\n",
    "\n",
    "umap_embeddings = umap.UMAP(n_neighbors=140, \n",
    "                            n_components=2, \n",
    "                            metric='cosine').fit_transform(corpus)\n",
    "\n",
    "# cluster = hdbscan.HDBSCAN(min_cluster_size=30,\n",
    "#                           metric='euclidean',                      \n",
    "#                           cluster_selection_method='eom').fit(umap_embeddings)\n",
    "\n",
    "# print(cluster.labels_.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "result = pd.DataFrame(umap_embeddings, columns=['x', 'y'])\n",
    "result['labels'] = cluster.labels_\n",
    "result['subject'] = lucy['검색어']\n",
    "fig = px.scatter(result, x='x', y='y', color='labels', hover_data=['subject'], width=750, height=750)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
